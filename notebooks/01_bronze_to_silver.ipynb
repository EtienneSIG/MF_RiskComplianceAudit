{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4d5726",
   "metadata": {},
   "source": [
    "# ðŸ”„ Bronze to Silver - Risk, Compliance & Audit\n",
    "\n",
    "Ce notebook transforme les donnÃ©es brutes (bronze) en tables Delta nettoyÃ©es (silver) dans le Lakehouse.\n",
    "\n",
    "## Ã‰tapes :\n",
    "1. Charger les fichiers CSV depuis Files/bronze/\n",
    "2. Appliquer les transformations (typage des dates, nettoyage)\n",
    "3. Ã‰crire les tables Delta dans le Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2771900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Load Bronze data\n",
    "print(\"ðŸ“¥ Chargement des donnÃ©es bronze...\")\n",
    "\n",
    "controls = spark.read.csv(\"Files/bronze/controls.csv\", header=True, inferSchema=True)\n",
    "executions = spark.read.csv(\"Files/bronze/control_executions.csv\", header=True, inferSchema=True)\n",
    "incidents = spark.read.csv(\"Files/bronze/incidents.csv\", header=True, inferSchema=True)\n",
    "remediation = spark.read.csv(\"Files/bronze/remediation_actions.csv\", header=True, inferSchema=True)\n",
    "vendors = spark.read.csv(\"Files/bronze/vendors.csv\", header=True, inferSchema=True)\n",
    "\n",
    "print(f\"âœ… Controls: {controls.count()} lignes\")\n",
    "print(f\"âœ… Executions: {executions.count()} lignes\")\n",
    "print(f\"âœ… Incidents: {incidents.count()} lignes\")\n",
    "print(f\"âœ… Remediation: {remediation.count()} lignes\")\n",
    "print(f\"âœ… Vendors: {vendors.count()} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Transform to Silver (typage, nettoyage)\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "print(\"ðŸ”§ Transformation des donnÃ©es...\")\n",
    "\n",
    "# Controls - dÃ©jÃ  propre\n",
    "controls_silver = controls\n",
    "\n",
    "# Control Executions - typage date\n",
    "executions_silver = executions \\\n",
    "    .withColumn(\"execution_date\", to_date(col(\"execution_date\")))\n",
    "\n",
    "# Incidents - typage date\n",
    "incidents_silver = incidents \\\n",
    "    .withColumn(\"detection_date\", to_date(col(\"detection_date\")))\n",
    "\n",
    "# Remediation Actions - typage dates multiples\n",
    "remediation_silver = remediation \\\n",
    "    .withColumn(\"start_date\", to_date(col(\"start_date\"))) \\\n",
    "    .withColumn(\"target_completion_date\", to_date(col(\"target_completion_date\"))) \\\n",
    "    .withColumn(\"completion_date\", to_date(col(\"completion_date\")))\n",
    "\n",
    "# Vendors - typage date et risk_score\n",
    "vendors_silver = vendors \\\n",
    "    .withColumn(\"last_audit_date\", to_date(col(\"last_audit_date\"))) \\\n",
    "    .withColumn(\"risk_score\", col(\"risk_score\").cast(\"float\"))\n",
    "\n",
    "print(\"âœ… Transformations appliquÃ©es!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Write to Delta Tables (Silver)\n",
    "print(\"ðŸ’¾ Ã‰criture des tables Delta...\")\n",
    "\n",
    "controls_silver.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"controls\")\n",
    "print(\"âœ… Table 'controls' crÃ©Ã©e\")\n",
    "\n",
    "executions_silver.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"control_executions\")\n",
    "print(\"âœ… Table 'control_executions' crÃ©Ã©e\")\n",
    "\n",
    "incidents_silver.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"incidents\")\n",
    "print(\"âœ… Table 'incidents' crÃ©Ã©e\")\n",
    "\n",
    "remediation_silver.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"remediation_actions\")\n",
    "print(\"âœ… Table 'remediation_actions' crÃ©Ã©e\")\n",
    "\n",
    "vendors_silver.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"vendors\")\n",
    "print(\"âœ… Table 'vendors' crÃ©Ã©e\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Silver tables created successfully!\")\n",
    "print(\"ðŸ“Š VÃ©rifiez les tables dans la section 'Tables' du Lakehouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17995e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Validation - AperÃ§u des tables crÃ©Ã©es\n",
    "print(\"ðŸ“Š AperÃ§u des tables crÃ©Ã©es:\\n\")\n",
    "\n",
    "print(\"=== CONTROLS ===\")\n",
    "spark.sql(\"SELECT * FROM controls LIMIT 5\").show()\n",
    "\n",
    "print(\"\\n=== CONTROL EXECUTIONS ===\")\n",
    "spark.sql(\"SELECT * FROM control_executions LIMIT 5\").show()\n",
    "\n",
    "print(\"\\n=== INCIDENTS ===\")\n",
    "spark.sql(\"SELECT * FROM incidents LIMIT 5\").show()\n",
    "\n",
    "print(\"\\n=== REMEDIATION ACTIONS ===\")\n",
    "spark.sql(\"SELECT * FROM remediation_actions LIMIT 5\").show()\n",
    "\n",
    "print(\"\\n=== VENDORS ===\")\n",
    "spark.sql(\"SELECT * FROM vendors LIMIT 5\").show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
