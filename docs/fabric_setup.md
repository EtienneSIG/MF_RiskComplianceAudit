# üöÄ Guide de D√©ploiement - Risk, Compliance & Audit Analytics sur Microsoft Fabric

## üìã Pr√©requis

- **Microsoft Fabric** : Capacit√© active (F64 minimum recommand√© pour AI features)
- **Workspace Fabric** : Droit Contributor minimum
- **Python 3.9+** : Pour g√©n√©ration de donn√©es (local)
- **Power BI Desktop** : (optionnel) pour tester Semantic Model localement

---

## üèóÔ∏è Architecture Cible

```mermaid
graph TB
    subgraph WORKSPACE["üè¢ FABRIC WORKSPACE"]
        subgraph LAKEHOUSE["üìä LAKEHOUSE"]
            BRONZE[("üì¶ Bronze<br/>CSV Files")]
            SILVER[("üî∑ Silver<br/>Delta Tables")]
            GOLD[("üèÜ Gold<br/>Aggregations")]
            AI_AUDIT[("üìÑ AI Shortcut<br/>audit_reports_txt")]
            AI_INCIDENT[("üìÑ AI Shortcut<br/>incident_desc_txt")]
            
            BRONZE --> SILVER
            SILVER --> GOLD
        end
        
        subgraph SEMANTIC["üìà SEMANTIC MODEL"]
            TABLES["‚úì Tables Silver<br/>‚úì Relations<br/>‚úì DAX Measures<br/>‚úì RLS (optionnel)"]
        end
        
        subgraph AGENT["ü§ñ DATA AGENT"]
            PERSONA["Persona: CCO<br/>+ AI Analysis"]
        end
        
        SILVER -.-> SEMANTIC
        SEMANTIC --> AGENT
        AI_AUDIT -.-> AGENT
        AI_INCIDENT -.-> AGENT
    end
    
    style WORKSPACE fill:#e3f2fd
    style LAKEHOUSE fill:#fff3e0
    style SEMANTIC fill:#e8f5e9
    style AGENT fill:#f3e5f5
    style SILVER fill:#4fc3f7
    style GOLD fill:#ffd54f
```

---

## üì¶ √âtape 1 : G√©n√©ration des Donn√©es (Local)

### 1.1 Cloner le Repository

```powershell
cd C:\Dev
git clone <your-repo-url> MF_RiskComplianceAudit
cd MF_RiskComplianceAudit
```

### 1.2 Installer les D√©pendances

```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

**requirements.txt :**
```
Faker==22.6.0
pandas==2.2.0
numpy==1.26.3
PyYAML==6.0.1
```

### 1.3 G√©n√©rer les Donn√©es

```powershell
python src/generate_data.py
```

**Sortie attendue :**
```
üöÄ Starting Risk, Compliance & Audit data generation...

‚úÖ Generated 149 controls
‚úÖ Generated 34091 control executions
‚úÖ Generated 200 incidents
‚úÖ Generated 186 remediation actions
‚úÖ Generated 100 vendors
‚úÖ Generated 100 audit reports
‚úÖ Generated 150 incident descriptions

üìä Summary:
   - Controls: 149
   - Control Executions: 34091
   - Incidents: 200
   - Remediation Actions: 186
   - Vendors: 100
   - Audit Reports: 100
   - Incident Descriptions: 150

üíæ Data saved to: data/raw/
```

### 1.4 Valider les Donn√©es

```powershell
python src/validate_schema.py
```

**Sortie attendue :**
```
üîç Starting Risk, Compliance & Audit data validation...

‚úÖ controls.csv: 7 columns, 149 rows
‚úÖ control_executions.csv: 6 columns, 34091 rows
‚úÖ incidents.csv: 8 columns, 200 rows
‚úÖ remediation_actions.csv: 9 columns, 186 rows
‚úÖ vendors.csv: 7 columns, 100 rows
‚úÖ Relationship control_executions ‚Üí controls: OK
‚úÖ Relationship incidents ‚Üí control_executions: OK
‚úÖ Relationship incidents ‚Üí vendors: OK
‚úÖ Relationship remediation_actions ‚Üí incidents: OK
‚úÖ audit_reports_txt/: 100 files
‚úÖ incident_descriptions_txt/: 150 files
‚úÖ Compliance Rate: 69.9% (realistic)

üéâ All validations passed!
```

---

## ‚òÅÔ∏è √âtape 2 : Cr√©er le Lakehouse dans Fabric

### 2.1 Cr√©er le Workspace

1. Ouvrir **Microsoft Fabric** ([https://app.fabric.microsoft.com](https://app.fabric.microsoft.com))
2. Cliquer **Workspaces** ‚Üí **+ New workspace**
3. Nom : `Risk_Compliance_Analytics`
4. Licence : F64 ou sup√©rieur (pour AI features)
5. Cliquer **Apply**

### 2.2 Cr√©er le Lakehouse

1. Dans le workspace, cliquer **+ New** ‚Üí **Lakehouse**
2. Nom : `Compliance_Lakehouse`
3. Cliquer **Create**

### 2.3 Cr√©er la Structure de Dossiers

Dans le Lakehouse Explorer (Files) :

```mermaid
graph TD
    FILES["üìÅ Files/"]
    BRONZE["üìÅ bronze/"]
    AUDIT["üìÅ audit_reports_txt/"]
    INCIDENT["üìÅ incident_descriptions_txt/"]
    
    FILES --> BRONZE
    FILES --> AUDIT
    FILES --> INCIDENT
    
    BRONZE --> CSV1["üìÑ controls.csv"]
    BRONZE --> CSV2["üìÑ control_executions.csv"]
    BRONZE --> CSV3["üìÑ incidents.csv"]
    BRONZE --> CSV4["üìÑ remediation_actions.csv"]
    BRONZE --> CSV5["üìÑ vendors.csv"]
    
    AUDIT --> TXT1["üìÑ 100 fichiers .txt"]
    INCIDENT --> TXT2["üìÑ 150 fichiers .txt"]
    
    style FILES fill:#e3f2fd
    style BRONZE fill:#fff3e0
    style AUDIT fill:#e8f5e9
    style INCIDENT fill:#f3e5f5
```

---

## üì§ √âtape 3 : Upload des Donn√©es

### 3.1 Upload via OneLake File Explorer (Recommand√©)

1. Installer **OneLake File Explorer** depuis Microsoft Store
2. Ouvrir OneLake File Explorer
3. Naviguer vers `Risk_Compliance_Analytics/Compliance_Lakehouse/Files`
4. Glisser-d√©poser :
   - `data/raw/*.csv` ‚Üí `bronze/`
   - `data/raw/audit_reports_txt/` ‚Üí `audit_reports_txt/`
   - `data/raw/incident_descriptions_txt/` ‚Üí `incident_descriptions_txt/`

### 3.2 Upload via Interface Web (Alternatif)

1. Dans Lakehouse, cliquer **Upload** ‚Üí **Upload folder**
2. S√©lectionner `data/raw/` localement
3. Attendre fin upload (peut prendre 3-5 min pour 34K rows + 250 files)

---

## üîÑ √âtape 4 : Transformation Bronze ‚Üí Silver ‚Üí Gold

### 4.1 Importer le Notebook Bronze ‚Üí Silver

Les notebooks de transformation sont d√©j√† cr√©√©s dans le dossier `notebooks/` du projet.

1. Dans le workspace Fabric, cliquer **Import** ‚Üí **Notebook**
2. S√©lectionner le fichier `notebooks/01_bronze_to_silver.ipynb`
3. Attendre l'import (quelques secondes)
4. Ouvrir le notebook import√©
5. **Ex√©cuter toutes les cellules** (bouton **Run all** ou Ctrl+Shift+Enter sur chaque cellule)

**Ce que fait le notebook :**
- ‚úÖ Charge les 5 fichiers CSV depuis Files/bronze/
- ‚úÖ Applique les transformations (typage des dates, nettoyage)
- ‚úÖ Cr√©e les tables Delta Silver dans le Lakehouse
- ‚úÖ Affiche un aper√ßu de validation

**V√©rification :** Apr√®s ex√©cution, v√©rifiez que les 5 tables apparaissent dans la section **Tables** du Lakehouse :
- controls
- control_executions
- incidents
- remediation_actions
- vendors

### 4.2 Importer le Notebook Silver ‚Üí Gold (Optionnel)

**‚ö†Ô∏è Important :** Les tables Gold sont optionnelles et servent uniquement pour des analyses Spark/notebooks. Le Semantic Model utilisera exclusivement les tables **Silver** (√âtape 5).

1. Dans le workspace Fabric, cliquer **Import** ‚Üí **Notebook**
2. S√©lectionner le fichier `notebooks/02_silver_to_gold.ipynb`
3. Attendre l'import
4. Ouvrir le notebook import√©
5. **Ex√©cuter toutes les cellules**

**Ce que fait le notebook :**
- ‚úÖ Charge les tables Silver depuis le Lakehouse
- ‚úÖ Cr√©e 4 tables Gold (agr√©gations pr√©-calcul√©es pour Spark) :
  - **gold_framework_metrics** : M√©triques de conformit√© par framework
  - **gold_incident_metrics** : Analyse incidents par type/s√©v√©rit√©
  - **gold_vendor_risk** : Analyse de risque vendors
  - **gold_remediation_metrics** : Performance des actions correctives
- ‚úÖ Affiche un r√©sum√© des tables cr√©√©es

**V√©rification :** Les 4 tables Gold doivent appara√Ætre dans la section **Tables** du Lakehouse

**üí° Usage des tables Gold :** Ces tables sont utiles pour des requ√™tes SQL directes ou des notebooks Spark, mais ne seront PAS utilis√©es dans le Semantic Model (pas de colonnes ID pour les relations).

---

## üîó √âtape 5 : Cr√©er le Semantic Model (Tables Silver uniquement)

### 5.1 Cr√©er Semantic Model depuis Lakehouse

**‚ö†Ô∏è Important :** Le Semantic Model utilise UNIQUEMENT les **tables Silver** qui contiennent toutes les colonnes ID n√©cessaires pour cr√©er les relations entre tables.

1. Dans Lakehouse, cliquer **New Semantic Model**
2. Nom : `Compliance_Model`
3. **S√©lectionner UNIQUEMENT les tables Silver :**
   - ‚úÖ controls
   - ‚úÖ control_executions
   - ‚úÖ incidents
   - ‚úÖ remediation_actions
   - ‚úÖ vendors
   - ‚ùå **NE PAS** s√©lectionner les tables gold_* (pas de colonnes ID)
4. Cliquer **Confirm**

**üí° Pourquoi Silver et non Gold ?**
- Les tables **Silver** contiennent toutes les colonnes (y compris les ID) permettant de cr√©er les relations
- Les tables **Gold** sont des agr√©gations sans colonnes ID ‚Üí impossible de cr√©er des relations
- Les mesures DAX dans le Semantic Model calculeront les agr√©gations √† partir des tables Silver

### 5.2 D√©finir les Relations (Tables Silver)

Ouvrir `Compliance_Model` ‚Üí **Model view**

**Cr√©er les relations suivantes entre les tables Silver :**

```mermaid
erDiagram
    CONTROLS ||--o{ CONTROL_EXECUTIONS : "control_id"
    CONTROL_EXECUTIONS ||--o{ INCIDENTS : "execution_id"
    VENDORS ||--o{ INCIDENTS : "vendor_id"
    INCIDENTS ||--o{ REMEDIATION_ACTIONS : "incident_id"
    
    CONTROLS {
        string control_id PK
        string control_name
        string framework
        string control_type
        string criticality
        string frequency
        string owner
    }
    
    CONTROL_EXECUTIONS {
        string execution_id PK
        string control_id FK
        date execution_date
        string status
        string findings
        string performed_by
    }
    
    INCIDENTS {
        string incident_id PK
        string execution_id FK
        string vendor_id FK
        string incident_type
        string severity
        date detection_date
        string status
        string assigned_to
    }
    
    REMEDIATION_ACTIONS {
        string remediation_id PK
        string incident_id FK
        string action_description
        string assigned_to
        date start_date
        date target_completion_date
        date completion_date
        string status
        float cost_usd
    }
    
    VENDORS {
        string vendor_id PK
        string vendor_name
        string service_type
        string criticality
        string compliance_status
        float annual_spend_usd
        date last_audit_date
        float risk_score
        string country
    }
```

**Param√®tres relations :**
- Cardinalit√© : Many-to-One (ou One-to-Many selon le sens)
- Cross-filter direction : Both (bidirectional)

**üí° Note :** Ces relations fonctionnent car les tables Silver contiennent toutes les colonnes ID n√©cessaires.

### 5.3 Ajouter Mesures DAX (Bas√©es sur Tables Silver)

Ouvrir `Compliance_Model` ‚Üí **Report view**

**üìã R√©f√©rence compl√®te :** Voir `docs/dax_measures.md` (30+ mesures DAX disponibles)

**‚ö†Ô∏è Important :** Toutes les mesures DAX utilisent les **tables Silver** pour b√©n√©ficier des relations entre tables. Les agr√©gations sont calcul√©es par DAX, pas pr√©-calcul√©es comme dans les tables Gold.

**Mesures essentielles √† cr√©er :**

Cliquer sur la table `control_executions` ‚Üí **New measure**

```dax
Compliance Rate = 
VAR ExecutionsPassed = CALCULATE(COUNTROWS(control_executions), control_executions[status] = "passed")
VAR TotalExecutions = COUNTROWS(control_executions)
RETURN
    DIVIDE(ExecutionsPassed, TotalExecutions, 0)
```

Cliquer sur la table `incidents` ‚Üí **New measure**

```dax
Open Incidents = 
CALCULATE(
    COUNTROWS(incidents),
    incidents[status] IN {"open", "investigating"}
)
```

```dax
Critical High Open = 
CALCULATE(
    COUNTROWS(incidents),
    incidents[severity] IN {"critical", "high"},
    incidents[status] IN {"open", "investigating"}
)
```

Cliquer sur la table `remediation_actions` ‚Üí **New measure**

```dax
MTTR = 
VAR RemediationCompleted = 
    FILTER(
        remediation_actions,
        remediation_actions[status] = "completed",
        remediation_actions[completion_date] <> BLANK()
    )
VAR MTTRTable = 
    ADDCOLUMNS(
        RemediationCompleted,
        "DaysToRemediate",
        DATEDIFF(
            remediation_actions[start_date],
            remediation_actions[completion_date],
            DAY
        )
    )
RETURN
    AVERAGEX(MTTRTable, [DaysToRemediate])
```

**üìã Voir `docs/dax_measures.md` pour les 30+ mesures compl√®tes**

**üí° Rappel :** Toutes les mesures DAX ci-dessus utilisent les tables **Silver** et exploitent les relations entre tables pour calculer les m√©triques. Les tables Gold ne sont pas utilis√©es dans le Semantic Model.

---

## ü§ñ √âtape 6 : Configurer AI Shortcut (Texte)

### 6.1 Cr√©er AI Shortcut pour Audit Reports

1. Dans Lakehouse, cliquer **Get data** ‚Üí **AI Shortcut**
2. Source : `Files/audit_reports_txt/`
3. Nom : `AI_Audit_Reports`
4. Settings :
   - Enable semantic chunking : ‚úÖ
   - Chunk size : 500 tokens
   - Overlap : 50 tokens
5. Cliquer **Create**

### 6.2 Cr√©er AI Shortcut pour Incident Descriptions

1. R√©p√©ter pour `Files/incident_descriptions_txt/`
2. Nom : `AI_Incident_Descriptions`
3. M√™mes settings

**‚è±Ô∏è Temps d'indexation :** 3-5 minutes pour 250 fichiers

---

## üß† √âtape 7 : Cr√©er et Configurer le Data Agent

### 7.1 Cr√©er Data Agent

1. Dans workspace, cliquer **+ New** ‚Üí **Data Agent**
2. Nom : `CCO_Compliance_Agent`
3. Data sources :
   - ‚úÖ Compliance_Model (Semantic Model)
   - ‚úÖ AI_Audit_Reports (AI Shortcut)
   - ‚úÖ AI_Incident_Descriptions (AI Shortcut)
4. Cliquer **Create**

### 7.2 Configurer Instructions Syst√®me

Copier le contenu de `docs/data_agent_instructions.md` dans **System Instructions**

**Snippet cl√© :**
```
You are David Laurent, Chief Compliance Officer at FinSecure Corp.
Your role is to ensure compliance across SOX, GDPR, ISO27001, and PCI-DSS frameworks.

Key Metrics:
- Compliance Rate > 90%
- Incident Response Time: Critical <24h, High <72h
- Mean Time To Remediate (MTTR) < 7 days
- Vendor Risk Score < 70

When asked about compliance, ALWAYS:
1. Check control_executions for compliance rate
2. Identify failed controls by framework
3. Analyze incidents linked to control failures
4. Extract insights from audit_reports if available
```

### 7.3 Tester le Data Agent

Poser questions de `docs/questions_demo.md` pour valider setup :

**Test 1 :**
> "Quel est le taux de conformit√© global ?"

**R√©ponse attendue :** 69.9% (vs target 90%)

**Test 2 :**
> "Extrais des audit reports les recommandations r√©currentes pour SOX"

**R√©ponse attendue :** Extraction texte mentionnant "automated alerts" (23√ó)

---

## ‚úÖ √âtape 8 : Validation Finale

### 8.1 Checklist de Validation

- [ ] 5 tables Delta cr√©√©es dans Lakehouse
- [ ] Relations correctement d√©finies dans Semantic Model
- [ ] 10+ mesures DAX disponibles
- [ ] 2 AI Shortcuts index√©s (audit_reports + incident_descriptions)
- [ ] Data Agent r√©pond correctement aux 3 premi√®res questions de `questions_demo.md`
- [ ] Compliance Rate calcul√© = ~69.9% (coh√©rent avec donn√©es g√©n√©r√©es)
- [ ] Framework breakdown : SOX 68.5%, GDPR 71.2%, ISO27001 70.1%, PCI-DSS 69.8%

### 8.2 Test de Performance

Poser la question complexe :
> "Cherche dans incident descriptions toute mention de 'offboarding' et identifie le contr√¥le qui devrait d√©tecter ces incidents"

**Temps de r√©ponse attendu :** < 30 secondes  
**Qualit√© r√©ponse :** Doit mentionner 18 incidents + CTRL_023 (Access Review) avec 58% compliance

---

## üéì √âtape 9 : D√©mo Ready !

Votre environnement est maintenant pr√™t pour :
- ‚úÖ D√©montrer Data Agent avec `questions_demo.md`
- ‚úÖ Raconter story `demo_story.md` ("L'Audit qui R√©v√®le")
- ‚úÖ Montrer AI extraction de texte
- ‚úÖ Calculer ROI automation (compliance 69.9% ‚Üí 81.2%)

---

## üêõ Troubleshooting

### Probl√®me : AI Shortcut ne retourne pas de r√©sultats

**Solution :**
- V√©rifier que fichiers .txt sont bien dans `Files/audit_reports_txt/` (pas dans Tables)
- Attendre fin d'indexation (Check **Settings** ‚Üí **Indexing status**)
- Re-cr√©er AI Shortcut si n√©cessaire

### Probl√®me : Relations ne se cr√©ent pas automatiquement

**Solution :**
- V√©rifier noms de colonnes EXACT (control_id, execution_id, etc.)
- Cr√©er relations manuellement dans Model view
- V√©rifier types de donn√©es (string pour IDs)

### Probl√®me : Mesures DAX retournent 0 ou BLANK

**Solution :**
- V√©rifier relations bidirectionnelles activ√©es
- V√©rifier filtres actifs dans rapport
- Tester mesure simple d'abord : `Total Executions = COUNTROWS(control_executions)`

---

## üìö Ressources

- **Documentation Fabric :** [https://learn.microsoft.com/fabric](https://learn.microsoft.com/fabric)
- **DAX Guide :** [https://dax.guide](https://dax.guide)
- **Data Agent Docs :** [https://learn.microsoft.com/fabric/data-agent](https://learn.microsoft.com/fabric/data-agent)

---

**Auteur :** Microsoft Fabric Demo Team  
**Version :** 1.0  
**Temps d'installation :** ~60 minutes  
**Date :** F√©vrier 2026
